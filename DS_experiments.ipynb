{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "similar-diana",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import numpy as np\n",
    "import datetime\n",
    "import calendar\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "remarkable-anthony",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_time_features(row):\n",
    "    time1, time2 = pd.to_datetime(row.at['start']), pd.to_datetime(row.at['end'])\n",
    "    #time = pd.to_datetime(row.at['created'])\n",
    "    #row.at['created'] = pd.to_datetime(row.at['created'])\n",
    "    if pd.isna(time1) or pd.isna(time2):\n",
    "        row.at['ds'] = np.nan\n",
    "        return row\n",
    "    duration = time2 - time1\n",
    "    duration_in_s = duration.total_seconds() \n",
    "    time_passed = divmod(duration_in_s, 3600)\n",
    "    ds = f\"{time1.year}/{time1.month}/{time1.day}T{time1.hour}:00:00+00:00\"\n",
    "    duration = int(time_passed[0])\n",
    "    row.at['duration'] = duration\n",
    "    row.at['ds'] = ds\n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "explicit-muscle",
   "metadata": {},
   "outputs": [],
   "source": [
    "fresh_history = fresh_history.apply(extract_time_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "removed-result",
   "metadata": {},
   "outputs": [],
   "source": [
    "fresh_history = pd.read_csv('fresh_history.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "impossible-check",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parking lot name</th>\n",
       "      <th>xml_id</th>\n",
       "      <th>Arrival in unix time</th>\n",
       "      <th>Departure in unix time</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>ds</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Burgdorf SBB ParkRail Bucherstrasse 2</td>\n",
       "      <td>17</td>\n",
       "      <td>1614038621</td>\n",
       "      <td>1.614053e+09</td>\n",
       "      <td>2021-02-23T01:03:41</td>\n",
       "      <td>2021-02-23T05:11:28</td>\n",
       "      <td>2021/2/23T1:00:00+00:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Burgdorf SBB ParkRail Bucherstrasse 2</td>\n",
       "      <td>17</td>\n",
       "      <td>1614059026</td>\n",
       "      <td>1.614065e+09</td>\n",
       "      <td>2021-02-23T06:43:46</td>\n",
       "      <td>2021-02-23T08:17:14</td>\n",
       "      <td>2021/2/23T6:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Burgdorf SBB ParkRail Bucherstrasse 2</td>\n",
       "      <td>17</td>\n",
       "      <td>1614078855</td>\n",
       "      <td>1.614079e+09</td>\n",
       "      <td>2021-02-23T12:14:15</td>\n",
       "      <td>2021-02-23T12:16:27</td>\n",
       "      <td>2021/2/23T12:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Burgdorf SBB ParkRail Bucherstrasse 2</td>\n",
       "      <td>17</td>\n",
       "      <td>1614084211</td>\n",
       "      <td>1.614085e+09</td>\n",
       "      <td>2021-02-23T13:43:31</td>\n",
       "      <td>2021-02-23T13:49:15</td>\n",
       "      <td>2021/2/23T13:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Burgdorf SBB ParkRail Bucherstrasse 2</td>\n",
       "      <td>17</td>\n",
       "      <td>1614145425</td>\n",
       "      <td>1.614146e+09</td>\n",
       "      <td>2021-02-24T06:43:45</td>\n",
       "      <td>2021-02-24T06:49:56</td>\n",
       "      <td>2021/2/24T6:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7139</th>\n",
       "      <td>Burgdorf SBB ParkRail Bucherstrasse 2</td>\n",
       "      <td>17</td>\n",
       "      <td>1613508284</td>\n",
       "      <td>1.613509e+09</td>\n",
       "      <td>2021-02-16T21:44:44</td>\n",
       "      <td>2021-02-16T21:50:37</td>\n",
       "      <td>2021/2/16T21:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7140</th>\n",
       "      <td>Burgdorf SBB ParkRail Bucherstrasse 2</td>\n",
       "      <td>17</td>\n",
       "      <td>1613565844</td>\n",
       "      <td>1.613574e+09</td>\n",
       "      <td>2021-02-17T13:44:04</td>\n",
       "      <td>2021-02-17T16:03:31</td>\n",
       "      <td>2021/2/17T13:00:00+00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7141</th>\n",
       "      <td>Burgdorf SBB ParkRail Bucherstrasse 2</td>\n",
       "      <td>17</td>\n",
       "      <td>1613601824</td>\n",
       "      <td>1.613602e+09</td>\n",
       "      <td>2021-02-17T23:43:44</td>\n",
       "      <td>2021-02-17T23:49:49</td>\n",
       "      <td>2021/2/17T23:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7142</th>\n",
       "      <td>Burgdorf SBB ParkRail Bucherstrasse 2</td>\n",
       "      <td>17</td>\n",
       "      <td>1613738553</td>\n",
       "      <td>1.613739e+09</td>\n",
       "      <td>2021-02-19T13:42:33</td>\n",
       "      <td>2021-02-19T13:49:53</td>\n",
       "      <td>2021/2/19T13:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7143</th>\n",
       "      <td>Burgdorf SBB ParkRail Bucherstrasse 2</td>\n",
       "      <td>17</td>\n",
       "      <td>1613900578</td>\n",
       "      <td>1.613924e+09</td>\n",
       "      <td>2021-02-21T10:42:58</td>\n",
       "      <td>2021-02-21T17:13:22</td>\n",
       "      <td>2021/2/21T10:00:00+00:00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7144 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Parking lot name  xml_id  Arrival in unix time  \\\n",
       "0     Burgdorf SBB ParkRail Bucherstrasse 2      17            1614038621   \n",
       "1     Burgdorf SBB ParkRail Bucherstrasse 2      17            1614059026   \n",
       "2     Burgdorf SBB ParkRail Bucherstrasse 2      17            1614078855   \n",
       "3     Burgdorf SBB ParkRail Bucherstrasse 2      17            1614084211   \n",
       "4     Burgdorf SBB ParkRail Bucherstrasse 2      17            1614145425   \n",
       "...                                     ...     ...                   ...   \n",
       "7139  Burgdorf SBB ParkRail Bucherstrasse 2      17            1613508284   \n",
       "7140  Burgdorf SBB ParkRail Bucherstrasse 2      17            1613565844   \n",
       "7141  Burgdorf SBB ParkRail Bucherstrasse 2      17            1613601824   \n",
       "7142  Burgdorf SBB ParkRail Bucherstrasse 2      17            1613738553   \n",
       "7143  Burgdorf SBB ParkRail Bucherstrasse 2      17            1613900578   \n",
       "\n",
       "      Departure in unix time                start                  end  \\\n",
       "0               1.614053e+09  2021-02-23T01:03:41  2021-02-23T05:11:28   \n",
       "1               1.614065e+09  2021-02-23T06:43:46  2021-02-23T08:17:14   \n",
       "2               1.614079e+09  2021-02-23T12:14:15  2021-02-23T12:16:27   \n",
       "3               1.614085e+09  2021-02-23T13:43:31  2021-02-23T13:49:15   \n",
       "4               1.614146e+09  2021-02-24T06:43:45  2021-02-24T06:49:56   \n",
       "...                      ...                  ...                  ...   \n",
       "7139            1.613509e+09  2021-02-16T21:44:44  2021-02-16T21:50:37   \n",
       "7140            1.613574e+09  2021-02-17T13:44:04  2021-02-17T16:03:31   \n",
       "7141            1.613602e+09  2021-02-17T23:43:44  2021-02-17T23:49:49   \n",
       "7142            1.613739e+09  2021-02-19T13:42:33  2021-02-19T13:49:53   \n",
       "7143            1.613924e+09  2021-02-21T10:42:58  2021-02-21T17:13:22   \n",
       "\n",
       "                            ds  duration  \n",
       "0      2021/2/23T1:00:00+00:00         4  \n",
       "1      2021/2/23T6:00:00+00:00         1  \n",
       "2     2021/2/23T12:00:00+00:00         0  \n",
       "3     2021/2/23T13:00:00+00:00         0  \n",
       "4      2021/2/24T6:00:00+00:00         0  \n",
       "...                        ...       ...  \n",
       "7139  2021/2/16T21:00:00+00:00         0  \n",
       "7140  2021/2/17T13:00:00+00:00         2  \n",
       "7141  2021/2/17T23:00:00+00:00         0  \n",
       "7142  2021/2/19T13:00:00+00:00         0  \n",
       "7143  2021/2/21T10:00:00+00:00         6  \n",
       "\n",
       "[7144 rows x 8 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burg_all = pd.read_csv('parkrail-burgdorf.csv', ';')\n",
    "burg_all['ds'] = 0\n",
    "burg_all['duration'] = 0\n",
    "burg_all = burg_all.rename(columns={\"Arrival in local time\": \"start\", \"Departure in local time\": \"end\"})\n",
    "burg_all = burg_all.apply(extract_time_features, axis=1)\n",
    "burg_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "derived-tattoo",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Burgdorf saved. 550 more to go.\n"
     ]
    }
   ],
   "source": [
    "facility_names = set(history.facility_name)\n",
    "facilities_sorted = {}\n",
    "counter = len(facility_names)\n",
    "spots = pd.read_csv('parkings.csv').drop(columns=['Unnamed: 0'])\n",
    "weekend_or_not = lambda x: 0 if x < 5 else 1 \n",
    "history = fresh_history\n",
    "\n",
    "\n",
    "for facility in [\"Burgdorf\"]:\n",
    "    #try:\n",
    "        ref = history.loc[history['facility_name'] == facility]\n",
    "        ref = ref.sort_values(by=['start'])\n",
    "        max_spots = int(spots.loc[spots['facility'] == str([facility])]['spaces'])\n",
    "        df = {\"ds\": [], 'facility': [], 'max_spots': [], 'weekend': [], 'weekday': [], 'hour': []}\n",
    "        for y in range(2):\n",
    "            for m in range(1, 13):\n",
    "                for d in range(1, calendar.monthrange([2020, 2021][y], m)[1]+1):\n",
    "                    for h in range(24):\n",
    "                      #print(df)\n",
    "                      date = f\"{[2020, 2021][y]}/{m}/{d}T{h}:00:00+00:00\"\n",
    "                      wd = pd.to_datetime(date).weekday()\n",
    "                      df['weekday'].append(wd)\n",
    "                      df['weekend'].append(weekend_or_not(wd))\n",
    "                      df['facility'].append(facility)\n",
    "                      df['ds'].append(date)\n",
    "                      df['max_spots'].append(max_spots)\n",
    "                      df['hour'].append(h)\n",
    "        df = pd.DataFrame(df)\n",
    "        df['taken_digit'] = 0\n",
    "        \n",
    "        for ix, entry in ref.iterrows():\n",
    "            try:\n",
    "                idx = df.loc[df['ds'] == entry.at['ds']].index[0]\n",
    "            except:\n",
    "                continue\n",
    "            for i in range(int(entry.at['duration'])):\n",
    "                df.at[idx + i, 'taken_digit'] += 1\n",
    "        \n",
    "        burg_all = burg_all.sort_values(by=['start'])\n",
    "        df['taken_paper'] = 0\n",
    "        for ix, entry in burg_all.iterrows():\n",
    "            try:\n",
    "                idx = df.loc[df['ds'] == entry.at['ds']].index[0]\n",
    "            except:\n",
    "                continue\n",
    "            for i in range(int(entry.at['duration'])):\n",
    "                df.at[idx + i, 'taken_paper'] += 1\n",
    "        df['taken_all'] = df['taken_digit'] + df['taken_paper']\n",
    "        df['perc_free'] = round((df['max_spots'] - df['taken_all']) / df['max_spots'] * 100, 2)\n",
    "        df.to_csv(\"tables/\" + facility + \"_pandemic.csv\", index=False)\n",
    "        counter -= 1\n",
    "        print(facility, 'saved.', counter, \"more to go.\")\n",
    "    #except Exception as e:\n",
    "    #    print(facility, \"failed, because:\")\n",
    "    #    print(e)\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "visible-characteristic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>facility_name</th>\n",
       "      <th>ds</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-27T07:30:00+00:00</td>\n",
       "      <td>2020-04-28T07:30:00+00:00</td>\n",
       "      <td>Rivera-Bironico</td>\n",
       "      <td>2020/4/27T7:00:00+00:00</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-27T07:30:00+00:00</td>\n",
       "      <td>2020-04-28T07:30:00+00:00</td>\n",
       "      <td>Fehraltorf</td>\n",
       "      <td>2020/4/27T7:00:00+00:00</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-27T07:25:00+00:00</td>\n",
       "      <td>2020-04-28T07:25:00+00:00</td>\n",
       "      <td>Bonstetten-Wettswil</td>\n",
       "      <td>2020/4/27T7:00:00+00:00</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-27T07:25:00+00:00</td>\n",
       "      <td>2020-04-28T07:25:00+00:00</td>\n",
       "      <td>St. Gallen St. Fiden</td>\n",
       "      <td>2020/4/27T7:00:00+00:00</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-27T07:25:00+00:00</td>\n",
       "      <td>2020-04-28T07:25:00+00:00</td>\n",
       "      <td>St. Gallen St. Fiden</td>\n",
       "      <td>2020/4/27T7:00:00+00:00</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344384</th>\n",
       "      <td>2020-02-13T06:55:00+00:00</td>\n",
       "      <td>2020-02-14T06:55:00+00:00</td>\n",
       "      <td>Horgen</td>\n",
       "      <td>2020/2/13T6:00:00+00:00</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344385</th>\n",
       "      <td>2021-02-13T10:25:00+00:00</td>\n",
       "      <td>2021-02-14T10:25:00+00:00</td>\n",
       "      <td>Oberbuchsiten</td>\n",
       "      <td>2021/2/13T10:00:00+00:00</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344386</th>\n",
       "      <td>2020-02-13T06:55:00+00:00</td>\n",
       "      <td>2020-02-14T06:55:00+00:00</td>\n",
       "      <td>Marthalen</td>\n",
       "      <td>2020/2/13T6:00:00+00:00</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344387</th>\n",
       "      <td>2021-02-13T10:10:00+00:00</td>\n",
       "      <td>2021-02-17T18:10:00+00:00</td>\n",
       "      <td>Grenchen Süd</td>\n",
       "      <td>2021/2/13T10:00:00+00:00</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344388</th>\n",
       "      <td>2020-02-13T06:55:00+00:00</td>\n",
       "      <td>2020-02-13T16:55:00+00:00</td>\n",
       "      <td>Versoix</td>\n",
       "      <td>2020/2/13T6:00:00+00:00</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>344389 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            start                        end  \\\n",
       "0       2020-04-27T07:30:00+00:00  2020-04-28T07:30:00+00:00   \n",
       "1       2020-04-27T07:30:00+00:00  2020-04-28T07:30:00+00:00   \n",
       "2       2020-04-27T07:25:00+00:00  2020-04-28T07:25:00+00:00   \n",
       "3       2020-04-27T07:25:00+00:00  2020-04-28T07:25:00+00:00   \n",
       "4       2020-04-27T07:25:00+00:00  2020-04-28T07:25:00+00:00   \n",
       "...                           ...                        ...   \n",
       "344384  2020-02-13T06:55:00+00:00  2020-02-14T06:55:00+00:00   \n",
       "344385  2021-02-13T10:25:00+00:00  2021-02-14T10:25:00+00:00   \n",
       "344386  2020-02-13T06:55:00+00:00  2020-02-14T06:55:00+00:00   \n",
       "344387  2021-02-13T10:10:00+00:00  2021-02-17T18:10:00+00:00   \n",
       "344388  2020-02-13T06:55:00+00:00  2020-02-13T16:55:00+00:00   \n",
       "\n",
       "               facility_name                        ds  duration  \n",
       "0            Rivera-Bironico   2020/4/27T7:00:00+00:00        24  \n",
       "1                 Fehraltorf   2020/4/27T7:00:00+00:00        24  \n",
       "2        Bonstetten-Wettswil   2020/4/27T7:00:00+00:00        24  \n",
       "3       St. Gallen St. Fiden   2020/4/27T7:00:00+00:00        24  \n",
       "4       St. Gallen St. Fiden   2020/4/27T7:00:00+00:00        24  \n",
       "...                      ...                       ...       ...  \n",
       "344384                Horgen   2020/2/13T6:00:00+00:00        24  \n",
       "344385         Oberbuchsiten  2021/2/13T10:00:00+00:00        24  \n",
       "344386             Marthalen   2020/2/13T6:00:00+00:00        24  \n",
       "344387          Grenchen Süd  2021/2/13T10:00:00+00:00       104  \n",
       "344388               Versoix   2020/2/13T6:00:00+00:00        10  \n",
       "\n",
       "[344389 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "tribal-jefferson",
   "metadata": {},
   "outputs": [],
   "source": [
    "rap = pd.read_csv('park-ride-rapperswil.csv', ';')\n",
    "rap.Datum = [pd.to_datetime(x) for x in rap.Datum]\n",
    "rap['hour'] = [x.hour for x in rap.Datum]\n",
    "rap = rap.sort_values(by='Datum').reset_index(drop=True)\n",
    "rap_dict = {x:y for x, y in zip(rap.Datum, rap['BELEGUNGSQUOTE (%)'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "detailed-departure",
   "metadata": {},
   "outputs": [],
   "source": [
    "spots = pd.read_csv('parkings.csv').drop(columns=['Unnamed: 0'])\n",
    "weekend_or_not = lambda x: 0 if x < 5 else 1 \n",
    "history = fresh_history\n",
    "facility_names = set(history.facility_name)\n",
    "facilities_sorted = {}\n",
    "counter = len(facility_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "disabled-report",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rapperswil saved. 547 more to go.\n"
     ]
    }
   ],
   "source": [
    "for facility in [\"Rapperswil\"]:\n",
    "    #try:\n",
    "        ref = history.loc[history['facility_name'] == facility]\n",
    "        ref = ref.sort_values(by=['start'])\n",
    "        ref.ds = [pd.to_datetime(x) for x in ref.ds]\n",
    "        max_spots = int(spots.loc[spots['facility'] == str([facility])]['spaces'])\n",
    "        df = {\"ds\": [], 'facility': [], 'max_spots': [], 'weekend': [], 'weekday': [], 'hour': []}\n",
    "        for y in range(2):\n",
    "            for m in range(1, 13):\n",
    "                for d in range(1, calendar.monthrange([2020, 2021][y], m)[1]+1):\n",
    "                    for h in range(24):\n",
    "                      #print(df)\n",
    "                      date = f\"{[2020, 2021][y]}-{m}-{d}T{h}:00:00+00:00\"\n",
    "                      wd = pd.to_datetime(date).weekday()\n",
    "                      df['weekday'].append(wd)\n",
    "                      df['weekend'].append(weekend_or_not(wd))\n",
    "                      df['facility'].append(facility)\n",
    "                      df['ds'].append(pd.to_datetime(date))\n",
    "                      df['max_spots'].append(max_spots)\n",
    "                      df['hour'].append(h)\n",
    "                      df['month'].append(m)\n",
    "                      df['day'].append(d)\n",
    "        df = pd.DataFrame(df)\n",
    "        df['taken_digit'] = 0\n",
    "        \n",
    "        for ix, entry in ref.iterrows():\n",
    "            try:\n",
    "                idx = df.loc[df['ds'] == entry.at['ds']].index[0]\n",
    "            except:\n",
    "                continue\n",
    "            for i in range(int(entry.at['duration'])):\n",
    "                df.at[idx + i, 'taken_digit'] += 1\n",
    "        \n",
    "        df['occupied'] = 0\n",
    "        for ix in range(3648, len(df['ds'])):\n",
    "            try:\n",
    "                df.at[ix, 'occupied'] = rap_dict[df['ds'][ix]]\n",
    "            except:\n",
    "                continue\n",
    "        df['taken_all'] = df['occupied'] * df['max_spots'] / 100\n",
    "        df['perc_free'] = 100 - df['occupied']\n",
    "        df.to_csv(\"tables/\" + facility + \".csv\", index=False)\n",
    "        counter -= 1\n",
    "        print(facility, 'saved.', counter, \"more to go.\")\n",
    "    #except Exception as e:\n",
    "    #    print(facility, \"failed, because:\")\n",
    "    #    print(e)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "forbidden-chrome",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Bahnhof_Haltestelle</th>\n",
       "      <th>Bezugsjahr</th>\n",
       "      <th>Kanton</th>\n",
       "      <th>Eigner</th>\n",
       "      <th>DTV</th>\n",
       "      <th>DWV</th>\n",
       "      <th>DNWV</th>\n",
       "      <th>Bemerkungen</th>\n",
       "      <th>Remarques</th>\n",
       "      <th>Note</th>\n",
       "      <th>Remarks</th>\n",
       "      <th>geopos</th>\n",
       "      <th>lod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AD</td>\n",
       "      <td>Aadorf</td>\n",
       "      <td>2018</td>\n",
       "      <td>TG</td>\n",
       "      <td>SBB</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>Durchschnittswert 2018 durch Streckensperrung ...</td>\n",
       "      <td>Valeur moyenne 2018 à la baisse en raison de l...</td>\n",
       "      <td>Valore medio 2018 compromesso dallo sbarrament...</td>\n",
       "      <td>Average value for 2018 impacted by line closure.</td>\n",
       "      <td>47.4881178542,8.90328450849</td>\n",
       "      <td>http://lod.opentransportdata.swiss/didok/8506013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA</td>\n",
       "      <td>Aarau</td>\n",
       "      <td>2018</td>\n",
       "      <td>AG</td>\n",
       "      <td>SBB</td>\n",
       "      <td>37900.0</td>\n",
       "      <td>44800.0</td>\n",
       "      <td>22700.0</td>\n",
       "      <td>Ohne AVA.</td>\n",
       "      <td>Sans AVA.</td>\n",
       "      <td>Senza AVA.</td>\n",
       "      <td>Without AVA.</td>\n",
       "      <td>47.3913553369,8.05125354274</td>\n",
       "      <td>http://lod.opentransportdata.swiss/didok/8502113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABO</td>\n",
       "      <td>Aarburg-Oftringen</td>\n",
       "      <td>2018</td>\n",
       "      <td>AG</td>\n",
       "      <td>SBB</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.3202667174,7.90820373354</td>\n",
       "      <td>http://lod.opentransportdata.swiss/didok/8502000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAT</td>\n",
       "      <td>Aathal</td>\n",
       "      <td>2018</td>\n",
       "      <td>ZH</td>\n",
       "      <td>SBB</td>\n",
       "      <td>740.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>610.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.3359563788,8.76561022548</td>\n",
       "      <td>http://lod.opentransportdata.swiss/didok/8503124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACLA</td>\n",
       "      <td>Acla da Fontauna</td>\n",
       "      <td>2018</td>\n",
       "      <td>GR</td>\n",
       "      <td>MGB</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.6971753494,8.84578125896</td>\n",
       "      <td>http://lod.opentransportdata.swiss/didok/8505180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Code Bahnhof_Haltestelle  Bezugsjahr Kanton Eigner      DTV      DWV  \\\n",
       "0    AD              Aadorf        2018     TG    SBB   1700.0   2000.0   \n",
       "1    AA               Aarau        2018     AG    SBB  37900.0  44800.0   \n",
       "2   ABO   Aarburg-Oftringen        2018     AG    SBB   2500.0   3000.0   \n",
       "3   AAT              Aathal        2018     ZH    SBB    740.0    800.0   \n",
       "4  ACLA    Acla da Fontauna        2018     GR    MGB     90.0     90.0   \n",
       "\n",
       "      DNWV                                        Bemerkungen  \\\n",
       "0   1000.0  Durchschnittswert 2018 durch Streckensperrung ...   \n",
       "1  22700.0                                          Ohne AVA.   \n",
       "2   1300.0                                                NaN   \n",
       "3    610.0                                                NaN   \n",
       "4     80.0                                                NaN   \n",
       "\n",
       "                                           Remarques  \\\n",
       "0  Valeur moyenne 2018 à la baisse en raison de l...   \n",
       "1                                          Sans AVA.   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                                Note  \\\n",
       "0  Valore medio 2018 compromesso dallo sbarrament...   \n",
       "1                                         Senza AVA.   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                            Remarks  \\\n",
       "0  Average value for 2018 impacted by line closure.   \n",
       "1                                      Without AVA.   \n",
       "2                                               NaN   \n",
       "3                                               NaN   \n",
       "4                                               NaN   \n",
       "\n",
       "                        geopos  \\\n",
       "0  47.4881178542,8.90328450849   \n",
       "1  47.3913553369,8.05125354274   \n",
       "2  47.3202667174,7.90820373354   \n",
       "3  47.3359563788,8.76561022548   \n",
       "4  46.6971753494,8.84578125896   \n",
       "\n",
       "                                                lod  \n",
       "0  http://lod.opentransportdata.swiss/didok/8506013  \n",
       "1  http://lod.opentransportdata.swiss/didok/8502113  \n",
       "2  http://lod.opentransportdata.swiss/didok/8502000  \n",
       "3  http://lod.opentransportdata.swiss/didok/8503124  \n",
       "4  http://lod.opentransportdata.swiss/didok/8505180  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passangers = pd.read_csv('passagierfrequenz.csv', ';')\n",
    "passangers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "female-sheep",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Horgen Oberdorf saved. 534 more to go.\n",
      "Ossingen saved. 533 more to go.\n",
      "Moos (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Schüpfheim saved. 532 more to go.\n",
      "Kehrsatz (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Bussigny saved. 531 more to go.\n",
      "Düdingen saved. 530 more to go.\n",
      "Busswil saved. 529 more to go.\n",
      "Auvernier saved. 528 more to go.\n",
      "Nebikon saved. 527 more to go.\n",
      "Alpnachstad (zb - Die Zentralbahn) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Rosé saved. 526 more to go.\n",
      "Räterschen saved. 525 more to go.\n",
      "Muttenz saved. 524 more to go.\n",
      "Erlenbach ZH saved. 523 more to go.\n",
      "Rolle saved. 522 more to go.\n",
      "Uerikon saved. 521 more to go.\n",
      "Arnegg saved. 520 more to go.\n",
      "Dinhard saved. 519 more to go.\n",
      "Baar saved. 518 more to go.\n",
      "Hinwil saved. 517 more to go.\n",
      "Richterswil saved. 516 more to go.\n",
      "Biglen (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Gibswil saved. 515 more to go.\n",
      "Stabio saved. 514 more to go.\n",
      "Schalunen (RBS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Chavornay saved. 513 more to go.\n",
      "Gelterkinden saved. 512 more to go.\n",
      "Le Day failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Schwarzenburg (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Stansstad (zb - Die Zentralbahn) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Urtenen (RBS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Cadenazzo saved. 511 more to go.\n",
      "Neuhausen saved. 510 more to go.\n",
      "Konolfingen saved. 509 more to go.\n",
      "Mosen saved. 508 more to go.\n",
      "Schwyz saved. 507 more to go.\n",
      "Kiesen saved. 506 more to go.\n",
      "St. Gallen saved. 505 more to go.\n",
      "Olten saved. 504 more to go.\n",
      "Stein am Rhein saved. 503 more to go.\n",
      "Gampel-Steg saved. 502 more to go.\n",
      "Lyss failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Wangen bei Olten saved. 501 more to go.\n",
      "Münchenstein saved. 500 more to go.\n",
      "Bätterkinden (RBS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Fraubrunnen (RBS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Kaltbrunn saved. 499 more to go.\n",
      "Kreuzlingen saved. 498 more to go.\n",
      "Bellinzona saved. 497 more to go.\n",
      "Brugg AG saved. 496 more to go.\n",
      "Arbon saved. 495 more to go.\n",
      "Mörschwil saved. 494 more to go.\n",
      "Siebnen-Wangen saved. 493 more to go.\n",
      "Egerkingen saved. 492 more to go.\n",
      "Grosshöchstetten (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Waldibrücke saved. 491 more to go.\n",
      "Thalwil saved. 490 more to go.\n",
      "Worb SBB saved. 489 more to go.\n",
      "Reichenbach im Kandertal (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Dagmersellen saved. 488 more to go.\n",
      "Baden saved. 487 more to go.\n",
      "Näfels-Mollis saved. 486 more to go.\n",
      "Steg saved. 485 more to go.\n",
      "Oberriet saved. 484 more to go.\n",
      "Uzwil saved. 483 more to go.\n",
      "Ecublens-Rue saved. 482 more to go.\n",
      "Bassersdorf saved. 481 more to go.\n",
      "Winterthur Wülflingen saved. 480 more to go.\n",
      "Solothurn (SBB) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Winterthur Seen saved. 479 more to go.\n",
      "Laufenburg saved. 478 more to go.\n",
      "Lyssach saved. 477 more to go.\n",
      "Dornach-Arlesheim saved. 476 more to go.\n",
      "Pfäffikon SZ saved. 475 more to go.\n",
      "Horgen saved. 474 more to go.\n",
      "Aadorf saved. 473 more to go.\n",
      "Oberburg (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Pieterlen saved. 472 more to go.\n",
      "Courtelary saved. 471 more to go.\n",
      "Nieder- und Oberurnen saved. 470 more to go.\n",
      "Döttingen saved. 469 more to go.\n",
      "Bad Ragaz saved. 468 more to go.\n",
      "Zwingen saved. 467 more to go.\n",
      "Eschlikon saved. 466 more to go.\n",
      "Grünenmatt (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Signau saved. 465 more to go.\n",
      "Arnex saved. 464 more to go.\n",
      "Stäfa saved. 463 more to go.\n",
      "Sierre failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Oberwangen saved. 462 more to go.\n",
      "Willisau (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Kerzers saved. 461 more to go.\n",
      "Marthalen saved. 460 more to go.\n",
      "Oey-Diemtigen (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Saland saved. 459 more to go.\n",
      "Goldach saved. 458 more to go.\n",
      "Toffen (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Ringgenberg (zb - Die Zentralbahn) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Wolhusen saved. 457 more to go.\n",
      "Embrach-Rorbas saved. 456 more to go.\n",
      "Thörishaus Dorf saved. 455 more to go.\n",
      "Fehraltorf failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Wiesendangen saved. 454 more to go.\n",
      "Ins (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Zell (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Sumiswald-Grünen (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Lucens saved. 453 more to go.\n",
      "Aarberg saved. 452 more to go.\n",
      "Fribourg failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Airolo saved. 451 more to go.\n",
      "Brienzwiler (zb - Die Zentralbahn) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Sissach saved. 450 more to go.\n",
      "Ballwil saved. 449 more to go.\n",
      "Gerlafingen (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Sion Vers le Pont failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Gampelen (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Aathal saved. 448 more to go.\n",
      "Aigle saved. 447 more to go.\n",
      "Seon saved. 446 more to go.\n",
      "Dietikon saved. 445 more to go.\n",
      "Kirchberg-Alchenflüh (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Martigny saved. 444 more to go.\n",
      "Oberried (zb - Die Zentralbahn) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Kloten saved. 443 more to go.\n",
      "Herrliberg-Feldmeilen saved. 442 more to go.\n",
      "Aesch BL failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Feldbach saved. 441 more to go.\n",
      "Faido saved. 440 more to go.\n",
      "Steffisburg (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Münchenbuchsee saved. 439 more to go.\n",
      "Allaman saved. 438 more to go.\n",
      "Gümmenen (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Leuk saved. 437 more to go.\n",
      "Benzenschwil saved. 436 more to go.\n",
      "Courgenay saved. 435 more to go.\n",
      "Buchs-Dällikon saved. 434 more to go.\n",
      "Bodio saved. 433 more to go.\n",
      "Walenstadt saved. 432 more to go.\n",
      "Zollikon saved. 431 more to go.\n",
      "Grolley saved. 430 more to go.\n",
      "Mendrisio saved. 429 more to go.\n",
      "Au ZH saved. 428 more to go.\n",
      "Cossonay-Penthalaz saved. 427 more to go.\n",
      "Andelfingen saved. 426 more to go.\n",
      "Oberbuchsiten saved. 425 more to go.\n",
      "Oberglatt saved. 424 more to go.\n",
      "Killwangen-Spreitenbach saved. 423 more to go.\n",
      "Büren an der Aare saved. 422 more to go.\n",
      "Wünnewil saved. 421 more to go.\n",
      "Urdorf saved. 420 more to go.\n",
      "Wald saved. 419 more to go.\n",
      "Seftigen (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Dietlikon saved. 418 more to go.\n",
      "Chiasso saved. 417 more to go.\n",
      "Brügg failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Emmenmatt saved. 416 more to go.\n",
      "Moutier saved. 415 more to go.\n",
      "Delémont saved. 414 more to go.\n",
      "Zäziwil saved. 413 more to go.\n",
      "Sevelen saved. 412 more to go.\n",
      "Kilchberg failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Brunnen saved. 411 more to go.\n",
      "Steinmaur saved. 410 more to go.\n",
      "Zollikofen SBB failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Zürich Tiefenbrunnen saved. 409 more to go.\n",
      "Puidoux-Chexbres failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Kandersteg (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Brünig-Hasliberg (zb - Die Zentralbahn) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Mitlödi saved. 408 more to go.\n",
      "Oensingen saved. 407 more to go.\n",
      "Mülenen (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Wolfenschiessen (zb - Die Zentralbahn) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Elgg saved. 406 more to go.\n",
      "Oensingen (SBB P+Rail Nord) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Herzogenbuchsee saved. 405 more to go.\n",
      "Corcelles-Sud saved. 404 more to go.\n",
      "Rüti ZH failed, because:\n",
      "cannot convert float NaN to integer\n",
      "Etzwilen saved. 403 more to go.\n",
      "Eschenz saved. 402 more to go.\n",
      "La Conversion failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Wil saved. 401 more to go.\n",
      "Le Landeron failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Zürich Seebach saved. 400 more to go.\n",
      "Niederweningen saved. 399 more to go.\n",
      "Opfikon saved. 398 more to go.\n",
      "Tecknau saved. 397 more to go.\n",
      "Marin-Epagnier (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Küsnacht (ZH) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Tägerwilen-Gottlieben saved. 396 more to go.\n",
      "Erlen saved. 395 more to go.\n",
      "Lamone-Cadempino Sud failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Wimmis (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Thalheim-Altikon saved. 394 more to go.\n",
      "Rämismühle-Zell saved. 393 more to go.\n",
      "Schübelbach-Buttikon saved. 392 more to go.\n",
      "Schmerikon saved. 391 more to go.\n",
      "Vevey saved. 390 more to go.\n",
      "Solothurn, Langzeitparkplatz (RBS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Niederried (zb - Die Zentralbahn) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Laufen saved. 389 more to go.\n",
      "Altendorf saved. 388 more to go.\n",
      "Islikon saved. 387 more to go.\n",
      "Puidoux saved. 386 more to go.\n",
      "Balsthal (OeBB) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Sempach-Neuenkirch failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Meiringen (zb - Die Zentralbahn) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Kölliken saved. 385 more to go.\n",
      "Neyruz saved. 384 more to go.\n",
      "Zollikofen (RBS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Cousset saved. 383 more to go.\n",
      "Münsterlingen-Scherzingen saved. 382 more to go.\n",
      "Trubschachen saved. 381 more to go.\n",
      "Porrentruy failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Palézieux saved. 380 more to go.\n",
      "Zollikofen saved. 379 more to go.\n",
      "Schachen LU saved. 378 more to go.\n",
      "San Nazzaro failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Bern Bümpliz Süd saved. 377 more to go.\n",
      "Aefligen (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Rheineck saved. 376 more to go.\n",
      "Wauwil saved. 375 more to go.\n",
      "Koblenz saved. 374 more to go.\n",
      "Turtmann saved. 373 more to go.\n",
      "Langnau saved. 372 more to go.\n",
      "Menznau (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Entlebuch saved. 371 more to go.\n",
      "Brienz (zb - Die Zentralbahn) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Taverne-Torricella saved. 370 more to go.\n",
      "Lanzenhäusern (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Hindelbank saved. 369 more to go.\n",
      "Ebikon saved. 368 more to go.\n",
      "Romont saved. 367 more to go.\n",
      "Winterthur Grüze saved. 366 more to go.\n",
      "Uttigen saved. 365 more to go.\n",
      "Uetikon saved. 364 more to go.\n",
      "Sulgen saved. 363 more to go.\n",
      "Kehlhof saved. 362 more to go.\n",
      "St. Gallen St. Fiden saved. 361 more to go.\n",
      "Murgenthal saved. 360 more to go.\n",
      "Grenchen Süd saved. 359 more to go.\n",
      "Andermatt, Parkplatz Süd (MGB) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Lachen saved. 358 more to go.\n",
      "Gümligen saved. 357 more to go.\n",
      "Lungern (zb - Die Zentralbahn) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Uznach saved. 356 more to go.\n",
      "Regensdorf-Watt saved. 355 more to go.\n",
      "Märstetten saved. 354 more to go.\n",
      "Kleindietwil (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Würenlos saved. 353 more to go.\n",
      "Schlatt saved. 352 more to go.\n",
      "Däniken saved. 351 more to go.\n",
      "Sursee (nur SBB-Anlagenteil Merkurstrasse) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Rekingen failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Cham saved. 350 more to go.\n",
      "Wettingen saved. 349 more to go.\n",
      "Dottikon-Dintikon saved. 348 more to go.\n",
      "Wallisellen saved. 347 more to go.\n",
      "Solothurn saved. 346 more to go.\n",
      "Kaiseraugst saved. 345 more to go.\n",
      "Bad Zurzach saved. 344 more to go.\n",
      "Othmarsingen saved. 343 more to go.\n",
      "Sarnen (zb - Die Zentralbahn) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Meilen saved. 342 more to go.\n",
      "Schinznach Bad saved. 341 more to go.\n",
      "Avenches saved. 340 more to go.\n",
      "Frutigen (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Romanshorn saved. 339 more to go.\n",
      "Les Hauts-Geneveys failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Wichtrach saved. 338 more to go.\n",
      "Niederweningen Dorf saved. 337 more to go.\n",
      "Uetendorf (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Ambrì-Piotta saved. 336 more to go.\n",
      "Lugano saved. 335 more to go.\n",
      "Satigny saved. 334 more to go.\n",
      "Granges-Marnand saved. 333 more to go.\n",
      "Landquart saved. 332 more to go.\n",
      "Glovelier saved. 331 more to go.\n",
      "Uster saved. 330 more to go.\n",
      "Rivera-Bironico saved. 329 more to go.\n",
      "Dielsdorf saved. 328 more to go.\n",
      "Lützelflüh-Goldbach (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Emmenbrücke saved. 327 more to go.\n",
      "St. Erhard-Knutwil saved. 326 more to go.\n",
      "Solothurn West saved. 325 more to go.\n",
      "Oberdiessbach (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Pratteln saved. 324 more to go.\n",
      "St-Maurice saved. 323 more to go.\n",
      "Zweisimmen (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Oberrüti saved. 322 more to go.\n",
      "Effretikon saved. 321 more to go.\n",
      "Wabern bei Bern (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Fribourg ancienne gare failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Rupperswil saved. 320 more to go.\n",
      "Kradolf saved. 319 more to go.\n",
      "Dübendorf saved. 318 more to go.\n",
      "Vallorbe saved. 317 more to go.\n",
      "Mettmenstetten saved. 316 more to go.\n",
      "Grellingen saved. 315 more to go.\n",
      "St-Imier saved. 314 more to go.\n",
      "Lotzwil (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Kaiserstuhl (zb - Die Zentralbahn) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Rüschlikon saved. 313 more to go.\n",
      "Diessenhofen saved. 312 more to go.\n",
      "Lenzburg saved. 311 more to go.\n",
      "Bern Bümpliz Nord (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Rikon saved. 310 more to go.\n",
      "Brig Autoquai failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Grandvaux saved. 309 more to go.\n",
      "Frenkendorf-Füllinsdorf saved. 308 more to go.\n",
      "Tägertschi saved. 307 more to go.\n",
      "Raron saved. 306 more to go.\n",
      "Stein-Säckingen saved. 305 more to go.\n",
      "Rickenbach-Attikon saved. 304 more to go.\n",
      "Wangen an der Aare saved. 303 more to go.\n",
      "Nänikon-Greifensee saved. 302 more to go.\n",
      "Sonceboz-Sombeval saved. 301 more to go.\n",
      "Dornach-Arlesheim (Tiefgarage) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Utzenstorf (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Steinen saved. 300 more to go.\n",
      "Flawil saved. 299 more to go.\n",
      "Hunzenschwil saved. 298 more to go.\n",
      "Melide saved. 297 more to go.\n",
      "Hochdorf saved. 296 more to go.\n",
      "St. Gallen Winkeln saved. 295 more to go.\n",
      "Eclépens saved. 294 more to go.\n",
      "Bern Wankdorf saved. 293 more to go.\n",
      "Knonau saved. 292 more to go.\n",
      "Sargans saved. 291 more to go.\n",
      "Monthey saved. 290 more to go.\n",
      "Gossau SG saved. 289 more to go.\n",
      "Küssnacht am Rigi saved. 288 more to go.\n",
      "Safenwil saved. 287 more to go.\n",
      "Zug Schutzengel saved. 286 more to go.\n",
      "Aesch (BL) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Rothenburg Dorf saved. 285 more to go.\n",
      "Solothurn West (SBB) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Altnau saved. 284 more to go.\n",
      "Zürich Altstetten / Westlink failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Lutry saved. 283 more to go.\n",
      "Buchs SG saved. 282 more to go.\n",
      "Bowil saved. 281 more to go.\n",
      "Riazzino saved. 280 more to go.\n",
      "Nottwil saved. 279 more to go.\n",
      "Siggenthal-Würenlingen saved. 278 more to go.\n",
      "Glattbrugg saved. 277 more to go.\n",
      "Burgdorf saved. 276 more to go.\n",
      "Berg saved. 275 more to go.\n",
      "Wildegg saved. 274 more to go.\n",
      "Ramsei (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Dallenwil (zb - Die Zentralbahn) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Burgistein (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Hettlingen saved. 273 more to go.\n",
      "Balerna saved. 272 more to go.\n",
      "Dornach-Arlesheim (Aussenplätze) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Gordola saved. 271 more to go.\n",
      "Bülach saved. 270 more to go.\n",
      "Rorschach saved. 269 more to go.\n",
      "Maroggia-Melano saved. 268 more to go.\n",
      "Ostermundigen saved. 267 more to go.\n",
      "Kreuzlingen Hafen saved. 266 more to go.\n",
      "Villeneuve saved. 265 more to go.\n",
      "Bütschwil saved. 264 more to go.\n",
      "Boll-Utzigen (RBS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Baldegg saved. 263 more to go.\n",
      "Immensee saved. 262 more to go.\n",
      "Versoix saved. 261 more to go.\n",
      "Thurnen (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Bauma saved. 260 more to go.\n",
      "Corcelles-Peseux saved. 259 more to go.\n",
      "Beinwil am See saved. 258 more to go.\n",
      "Biasca saved. 257 more to go.\n",
      "Giubiasco saved. 256 more to go.\n",
      "Amriswil saved. 255 more to go.\n",
      "Riedbach (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Croy-Romainmôtier saved. 254 more to go.\n",
      "Grafenried (RBS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Boudry saved. 253 more to go.\n",
      "Heimberg (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Sion saved. 252 more to go.\n",
      "Illnau saved. 251 more to go.\n",
      "Travers saved. 250 more to go.\n",
      "Grenchen Nord (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Eglisau saved. 249 more to go.\n",
      "Hedingen saved. 248 more to go.\n",
      "Hendschiken saved. 247 more to go.\n",
      "Rotkreuz saved. 246 more to go.\n",
      "Müllheim-Wigoltingen saved. 245 more to go.\n",
      "Estavayer-le-Lac failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Suberg-Grossaffoltern saved. 244 more to go.\n",
      "La Sarraz failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Aarburg-Oftringen saved. 243 more to go.\n",
      "Güttingen saved. 242 more to go.\n",
      "Lengnau saved. 241 more to go.\n",
      "Tannay saved. 240 more to go.\n",
      "Biberist (RBS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Möhlin saved. 239 more to go.\n",
      "Solothurn West SBB failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Rubigen saved. 238 more to go.\n",
      "Heerbrugg saved. 237 more to go.\n",
      "Mumpf saved. 236 more to go.\n",
      "Schönenwerd failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Oberwinterthur saved. 235 more to go.\n",
      "Boswil-Bünzen saved. 234 more to go.\n",
      "Murten saved. 233 more to go.\n",
      "Erstfeld saved. 232 more to go.\n",
      "Sirnach saved. 231 more to go.\n",
      "Egnach saved. 230 more to go.\n",
      "Schlattingen saved. 229 more to go.\n",
      "Altdorf saved. 228 more to go.\n",
      "Grandson saved. 227 more to go.\n",
      "St. Gallen Bruggen saved. 226 more to go.\n",
      "Mägenwil saved. 225 more to go.\n",
      "Giswil (zb - Die Zentralbahn) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Meggen saved. 224 more to go.\n",
      "Birmensdorf ZH saved. 223 more to go.\n",
      "Salez-Sennwald saved. 222 more to go.\n",
      "Turgi saved. 221 more to go.\n",
      "Erlenbach (ZH) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Ziegelbrücke saved. 220 more to go.\n",
      "La Plaine failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Worbboden (RBS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Le Locle failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Vernayaz saved. 219 more to go.\n",
      "Schänis failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Rapperswil saved. 218 more to go.\n",
      "Oberrieden Dorf saved. 217 more to go.\n",
      "Lamone-Cadempino saved. 216 more to go.\n",
      "Deisswil (RBS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Dulliken saved. 215 more to go.\n",
      "Wila saved. 214 more to go.\n",
      "Littau saved. 213 more to go.\n",
      "Müntschemier (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Schöfflisdorf-Oberweningen saved. 212 more to go.\n",
      "Arth-Goldau saved. 211 more to go.\n",
      "Niederhasli saved. 210 more to go.\n",
      "Pfungen saved. 209 more to go.\n",
      "Klus (OeBB) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Liestal saved. 208 more to go.\n",
      "Colombier saved. 207 more to go.\n",
      "Frick saved. 206 more to go.\n",
      "Locle-Col-des-Roches failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Niederglatt saved. 205 more to go.\n",
      "Belfaux CFF saved. 204 more to go.\n",
      "Moudon saved. 203 more to go.\n",
      "Rebstein-Marbach saved. 202 more to go.\n",
      "Flamatt saved. 201 more to go.\n",
      "Au SG saved. 200 more to go.\n",
      "Castione-Arbedo saved. 199 more to go.\n",
      "Weinfelden saved. 198 more to go.\n",
      "Neuchâtel-Serrières failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Mezzovico saved. 197 more to go.\n",
      "Schwerzenbach failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "St-Blaise failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Rümlang saved. 196 more to go.\n",
      "Thun saved. 195 more to go.\n",
      "Brig saved. 194 more to go.\n",
      "Chur saved. 193 more to go.\n",
      "Dachsen saved. 192 more to go.\n",
      "Coppet saved. 191 more to go.\n",
      "Wohlen failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Lavorgo saved. 190 more to go.\n",
      "Stammheim saved. 189 more to go.\n",
      "Oberrieden See failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Gasel (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Fischenthal saved. 188 more to go.\n",
      "Cressier failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Schüpfen saved. 187 more to go.\n",
      "Kempten saved. 186 more to go.\n",
      "Bürglen saved. 185 more to go.\n",
      "Mellingen-Heitersberg failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Glattfelden saved. 184 more to go.\n",
      "Felben-Wellhausen saved. 183 more to go.\n",
      "Sachseln (zb - Die Zentralbahn) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Ranzo-S. Abbondio saved. 182 more to go.\n",
      "Hasle-Rüegsau (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Uttwil saved. 181 more to go.\n",
      "Hitzkirch saved. 180 more to go.\n",
      "Henggart saved. 179 more to go.\n",
      "Gisikon-Root saved. 178 more to go.\n",
      "Otelfingen saved. 177 more to go.\n",
      "Zollikofen (SBB) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Rafz saved. 176 more to go.\n",
      "Bilten saved. 175 more to go.\n",
      "Zweidlen saved. 174 more to go.\n",
      "Tenero saved. 173 more to go.\n",
      "Schwanden saved. 172 more to go.\n",
      "Payerne saved. 171 more to go.\n",
      "Bonstetten-Wettswil saved. 170 more to go.\n",
      "La Chaux-de-Fonds saved. 169 more to go.\n",
      "Göschenen saved. 168 more to go.\n",
      "Mühlau saved. 167 more to go.\n",
      "Capolago-Riva S. Vitale saved. 166 more to go.\n",
      "Magadino-Vira saved. 165 more to go.\n",
      "Worblaufen Ost (RBS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Feuerthalen saved. 164 more to go.\n",
      "Les Geneveys-sur-Coffrane failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Hüntwangen-Wil saved. 163 more to go.\n",
      "Glarus saved. 162 more to go.\n",
      "Männedorf saved. 161 more to go.\n",
      "Jegenstorf (RBS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Turbenthal saved. 160 more to go.\n",
      "Yverdon-les-Bains saved. 159 more to go.\n",
      "Bettlach saved. 158 more to go.\n",
      "Birrwil saved. 157 more to go.\n",
      "Worb Dorf, Parkhaus (RBS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Courtételle saved. 156 more to go.\n",
      "Sins saved. 155 more to go.\n",
      "Gland saved. 154 more to go.\n",
      "Deitingen saved. 153 more to go.\n",
      "Kollbrunn saved. 152 more to go.\n",
      "Lengwil saved. 151 more to go.\n",
      "Seuzach saved. 150 more to go.\n",
      "Luterbach-Attisholz saved. 149 more to go.\n",
      "Sennhof-Kyburg saved. 148 more to go.\n",
      "Därstetten (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Münsingen saved. 147 more to go.\n",
      "Flums saved. 146 more to go.\n",
      "Lausen saved. 145 more to go.\n",
      "Engelberg (zb - Die Zentralbahn) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Pfäffikon ZH saved. 144 more to go.\n",
      "Reichenburg saved. 143 more to go.\n",
      "Schmitten saved. 142 more to go.\n",
      "Interlaken West (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Rothenburg saved. 141 more to go.\n",
      "Rosshäusern (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Malters saved. 140 more to go.\n",
      "Hergiswil (zb - Die Zentralbahn) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Küsnacht ZH saved. 139 more to go.\n",
      "Rothrist saved. 138 more to go.\n",
      "Kaufdorf (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Maienfeld saved. 137 more to go.\n",
      "Zug saved. 136 more to go.\n",
      "Eiken saved. 135 more to go.\n",
      "Thörishaus Station saved. 134 more to go.\n",
      "Gettnau (BLS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Rheinfelden saved. 133 more to go.\n",
      "Oberentfelden saved. 132 more to go.\n",
      "Hägendorf saved. 131 more to go.\n",
      "Nyon saved. 130 more to go.\n",
      "Selzach saved. 129 more to go.\n",
      "Hauptwil saved. 128 more to go.\n",
      "S. Antonino saved. 127 more to go.\n",
      "Reiden saved. 126 more to go.\n",
      "Escholzmatt saved. 125 more to go.\n",
      "Lohn-Lüterkofen (RBS) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Muri failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Olten Hammer saved. 124 more to go.\n",
      "Bex saved. 123 more to go.\n",
      "Alpnach Dorf (zb - Die Zentralbahn) failed, because:\n",
      "cannot convert the series to <class 'int'>\n",
      "Solothurn SBB failed, because:\n",
      "cannot convert the series to <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "for facility in facility_names:\n",
    "    try:\n",
    "        ref = history.loc[history['facility_name'] == facility]\n",
    "        pas = passangers.loc[passangers['Bahnhof_Haltestelle'] == facility]\n",
    "        max_spots = int(spots.loc[spots['facility'] == str([facility])]['spaces'])\n",
    "        try:\n",
    "            dtv = pas.iloc[0]['DTV']\n",
    "        except:\n",
    "            dtv = max_spots * 20\n",
    "        ref = ref.sort_values(by=['start'])\n",
    "        ref.ds = [pd.to_datetime(x) for x in ref.ds]\n",
    "        df = {\"ds\": [], 'facility': [], 'max_spots': [], 'weekend': [], 'weekday': [], 'hour': [], 'month': [], 'day': [], 'traffic': []}\n",
    "        for y in range(2):\n",
    "            for m in range(1, 13):\n",
    "                for d in range(1, calendar.monthrange([2020, 2021][y], m)[1]+1):\n",
    "                    for h in range(24):\n",
    "                      #print(df)\n",
    "                      date = f\"{[2020, 2021][y]}-{m}-{d}T{h}:00:00+00:00\"\n",
    "                      wd = pd.to_datetime(date).weekday()\n",
    "                      df['weekday'].append(wd)\n",
    "                      df['weekend'].append(weekend_or_not(wd))\n",
    "                      df['facility'].append(facility)\n",
    "                      df['ds'].append(pd.to_datetime(date))\n",
    "                      df['max_spots'].append(max_spots)\n",
    "                      df['hour'].append(h)\n",
    "                      df['month'].append(m)\n",
    "                      df['day'].append(d)\n",
    "                      df['traffic'].append(dtv)\n",
    "        df = pd.DataFrame(df)\n",
    "        df['taken_digit'] = 0\n",
    "        for ix, entry in ref.iterrows():\n",
    "            try:\n",
    "                idx = df.loc[df['ds'] == entry.at['ds']].index[0]\n",
    "            except:\n",
    "                continue\n",
    "            for i in range(int(entry.at['duration'])):\n",
    "                df.at[idx + i, 'taken_digit'] += 1\n",
    "        \n",
    "        # I assume that digital tickets are on avarage 15% of all the tickets\n",
    "        df['extrapolated'] = (df['taken_digit'] * 100 / 15).astype('int')\n",
    "\n",
    "        df['perc_free'] = ((df['max_spots'] - df['extrapolated']) / df['max_spots'] * 100).map(lambda x: 0 if x < 0 else round(x, 2))\n",
    "        df.to_csv(\"tables/\" + facility + \".csv\", index=False)\n",
    "        counter -= 1\n",
    "        print(facility, 'saved.', counter, \"more to go.\")\n",
    "    except Exception as e:\n",
    "        print(facility, \"failed, because:\")\n",
    "        print(e)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neutral-bangladesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "for facility in facility_names:\n",
    "    try:\n",
    "        ref = history.loc[history['facility_name'] == facility]\n",
    "        pas = passangers.loc[passangers['Bahnhof_Haltestelle'] == facility]\n",
    "        max_spots = int(spots.loc[spots['facility'] == str([facility])]['spaces'])\n",
    "        try:\n",
    "            dtv = pas.iloc[0]['DTV']\n",
    "        except:\n",
    "            dtv = max_spots * 20\n",
    "        ref = ref.sort_values(by=['start'])\n",
    "        ref.ds = [pd.to_datetime(x) for x in ref.ds]\n",
    "        df = {\"ds\": [], 'facility': [], 'max_spots': [], 'weekend': [], 'weekday': [], 'hour': [], 'month': [], 'day': [], 'traffic': []}\n",
    "        for y in range(2):\n",
    "            for m in range(1, 13):\n",
    "                for d in range(1, calendar.monthrange([2020, 2021][y], m)[1]+1):\n",
    "                    for h in range(24):\n",
    "                      #print(df)\n",
    "                      date = f\"{[2020, 2021][y]}-{m}-{d}T{h}:00:00+00:00\"\n",
    "                      wd = pd.to_datetime(date).weekday()\n",
    "                      df['weekday'].append(wd)\n",
    "                      df['weekend'].append(weekend_or_not(wd))\n",
    "                      df['facility'].append(facility)\n",
    "                      df['ds'].append(pd.to_datetime(date))\n",
    "                      df['max_spots'].append(max_spots)\n",
    "                      df['hour'].append(h)\n",
    "                      df['month'].append(m)\n",
    "                      df['day'].append(d)\n",
    "                      df['traffic'].append(dtv)\n",
    "        df = pd.DataFrame(df)\n",
    "        df['taken_digit'] = 0\n",
    "        for ix, entry in ref.iterrows():\n",
    "            try:\n",
    "                idx = df.loc[df['ds'] == entry.at['ds']].index[0]\n",
    "            except:\n",
    "                continue\n",
    "            for i in range(int(entry.at['duration'])):\n",
    "                df.at[idx + i, 'taken_digit'] += 1\n",
    "        \n",
    "        # I assume that digital tickets are on avarage 15% of all the tickets\n",
    "        df['extrapolated'] = (df['taken_digit'] * 100 / 15).astype('int')\n",
    "\n",
    "        df['perc_free'] = ((df['max_spots'] - df['extrapolated']) / df['max_spots'] * 100).map(lambda x: 0 if x < 0 else round(x, 2))\n",
    "        df.to_csv(\"tables/\" + facility + \".csv\", index=False)\n",
    "        counter -= 1\n",
    "        print(facility, 'saved.', counter, \"more to go.\")\n",
    "    except Exception as e:\n",
    "        print(facility, \"failed, because:\")\n",
    "        print(e)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "killing-safety",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>facility</th>\n",
       "      <th>max_spots</th>\n",
       "      <th>weekend</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "      <th>taken_digit</th>\n",
       "      <th>occupied</th>\n",
       "      <th>taken_all</th>\n",
       "      <th>perc_free</th>\n",
       "      <th>taken_paper</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-06-01 00:00:00+00:00</th>\n",
       "      <td>Rapperswil</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.6</td>\n",
       "      <td>88</td>\n",
       "      <td>19.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-01 01:00:00+00:00</th>\n",
       "      <td>Rapperswil</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>94</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-01 02:00:00+00:00</th>\n",
       "      <td>Rapperswil</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>93</td>\n",
       "      <td>10.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-01 03:00:00+00:00</th>\n",
       "      <td>Rapperswil</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>93</td>\n",
       "      <td>10.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-01 04:00:00+00:00</th>\n",
       "      <td>Rapperswil</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>94</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             facility  max_spots  weekend  weekday  hour  \\\n",
       "ds                                                                         \n",
       "2020-06-01 00:00:00+00:00  Rapperswil        180        0        0     0   \n",
       "2020-06-01 01:00:00+00:00  Rapperswil        180        0        0     1   \n",
       "2020-06-01 02:00:00+00:00  Rapperswil        180        0        0     2   \n",
       "2020-06-01 03:00:00+00:00  Rapperswil        180        0        0     3   \n",
       "2020-06-01 04:00:00+00:00  Rapperswil        180        0        0     4   \n",
       "\n",
       "                           taken_digit  occupied  taken_all  perc_free  \\\n",
       "ds                                                                       \n",
       "2020-06-01 00:00:00+00:00            2      12.0       21.6         88   \n",
       "2020-06-01 01:00:00+00:00            2       6.0       10.8         94   \n",
       "2020-06-01 02:00:00+00:00            2       7.0       12.6         93   \n",
       "2020-06-01 03:00:00+00:00            2       7.0       12.6         93   \n",
       "2020-06-01 04:00:00+00:00            2       6.0       10.8         94   \n",
       "\n",
       "                           taken_paper  \n",
       "ds                                      \n",
       "2020-06-01 00:00:00+00:00         19.6  \n",
       "2020-06-01 01:00:00+00:00          8.8  \n",
       "2020-06-01 02:00:00+00:00         10.6  \n",
       "2020-06-01 03:00:00+00:00         10.6  \n",
       "2020-06-01 04:00:00+00:00          8.8  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rapperswil = pd.read_csv('tables/rapperswil_extra.csv', index_col = 'ds')\n",
    "rapperswil.index = pd.to_datetime(rapperswil.index)\n",
    "rapperswil['occupied'] = rapperswil['occupied'].replace({0:np.nan})\n",
    "rapperswil['taken_all'] = rapperswil['taken_all']\n",
    "rapperswil['taken_paper'] = rapperswil['taken_all'] - rapperswil['taken_digit']\n",
    "rapperswil.interpolate(method='polynomial', order=2, inplace=True)\n",
    "rapperswil = rapperswil.dropna()\n",
    "rapperswil['occupied'] = rapperswil['occupied']\n",
    "rapperswil.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "furnished-symposium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.46560822960286"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rapperswil['perc_paper'] = rapperswil['taken_paper'] / rapperswil['taken_all'] * 100\n",
    "rapperswil['perc_paper'].where(rapperswil['perc_paper'] >= 0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "earlier-medicine",
   "metadata": {},
   "outputs": [],
   "source": [
    "burg_all['ds'] = 0\n",
    "burg_all['duration'] = 0\n",
    "burg_all = burg_all.rename(columns={\"Arrival in local time\": \"start\", \"Departure in local time\": \"end\"})\n",
    "burg_all = burg_all.apply(extract_time_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "approved-missile",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parking lot name</th>\n",
       "      <th>xml_id</th>\n",
       "      <th>Arrival in unix time</th>\n",
       "      <th>Departure in unix time</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>ds</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Burgdorf SBB ParkRail Bucherstrasse 2</td>\n",
       "      <td>17</td>\n",
       "      <td>1614038621</td>\n",
       "      <td>1.614053e+09</td>\n",
       "      <td>2021-02-23T01:03:41</td>\n",
       "      <td>2021-02-23T05:11:28</td>\n",
       "      <td>2021/2/23T1:00:00+00:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Burgdorf SBB ParkRail Bucherstrasse 2</td>\n",
       "      <td>17</td>\n",
       "      <td>1614059026</td>\n",
       "      <td>1.614065e+09</td>\n",
       "      <td>2021-02-23T06:43:46</td>\n",
       "      <td>2021-02-23T08:17:14</td>\n",
       "      <td>2021/2/23T6:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Burgdorf SBB ParkRail Bucherstrasse 2</td>\n",
       "      <td>17</td>\n",
       "      <td>1614078855</td>\n",
       "      <td>1.614079e+09</td>\n",
       "      <td>2021-02-23T12:14:15</td>\n",
       "      <td>2021-02-23T12:16:27</td>\n",
       "      <td>2021/2/23T12:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Burgdorf SBB ParkRail Bucherstrasse 2</td>\n",
       "      <td>17</td>\n",
       "      <td>1614084211</td>\n",
       "      <td>1.614085e+09</td>\n",
       "      <td>2021-02-23T13:43:31</td>\n",
       "      <td>2021-02-23T13:49:15</td>\n",
       "      <td>2021/2/23T13:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Burgdorf SBB ParkRail Bucherstrasse 2</td>\n",
       "      <td>17</td>\n",
       "      <td>1614145425</td>\n",
       "      <td>1.614146e+09</td>\n",
       "      <td>2021-02-24T06:43:45</td>\n",
       "      <td>2021-02-24T06:49:56</td>\n",
       "      <td>2021/2/24T6:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Parking lot name  xml_id  Arrival in unix time  \\\n",
       "0  Burgdorf SBB ParkRail Bucherstrasse 2      17            1614038621   \n",
       "1  Burgdorf SBB ParkRail Bucherstrasse 2      17            1614059026   \n",
       "2  Burgdorf SBB ParkRail Bucherstrasse 2      17            1614078855   \n",
       "3  Burgdorf SBB ParkRail Bucherstrasse 2      17            1614084211   \n",
       "4  Burgdorf SBB ParkRail Bucherstrasse 2      17            1614145425   \n",
       "\n",
       "   Departure in unix time                start                  end  \\\n",
       "0            1.614053e+09  2021-02-23T01:03:41  2021-02-23T05:11:28   \n",
       "1            1.614065e+09  2021-02-23T06:43:46  2021-02-23T08:17:14   \n",
       "2            1.614079e+09  2021-02-23T12:14:15  2021-02-23T12:16:27   \n",
       "3            1.614085e+09  2021-02-23T13:43:31  2021-02-23T13:49:15   \n",
       "4            1.614146e+09  2021-02-24T06:43:45  2021-02-24T06:49:56   \n",
       "\n",
       "                         ds  duration  \n",
       "0   2021/2/23T1:00:00+00:00         4  \n",
       "1   2021/2/23T6:00:00+00:00         1  \n",
       "2  2021/2/23T12:00:00+00:00         0  \n",
       "3  2021/2/23T13:00:00+00:00         0  \n",
       "4   2021/2/24T6:00:00+00:00         0  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burg_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "dying-monitoring",
   "metadata": {},
   "outputs": [],
   "source": [
    "burg['taken_all'] = df['taken']\n",
    "burg['paper_tickets'] = df['taken'] - burg['taken_digit']\n",
    "burg['y'] = burg['taken_all'] / burg['max_spots']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "isolated-drain",
   "metadata": {},
   "outputs": [],
   "source": [
    "burgdorf = burgdorf[:10081]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "distinct-institute",
   "metadata": {},
   "outputs": [],
   "source": [
    "burgdorf.to_csv('burgdorf_complete.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "internal-gateway",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93.41398673570765"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burg = pd.read_csv('tables/Burgdorf_pandemic.csv')\n",
    "burg = burg.loc[burg['taken_paper'] != 0]\n",
    "burg['perc_paper'] = burg['taken_paper'] / burg['taken_all'] * 100\n",
    "burg['perc_paper'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "assured-plenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "progressive-signal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['facility', 'max_spots', 'weekend', 'weekday', 'hour', 'taken_digit',\n",
       "       'occupied', 'taken_all', 'perc_free'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rapperswil.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "seeing-gambling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['max_spots', 'weekend', 'weekday', 'hour'], dtype='object')\n",
      "The mean squared error (MSE) on test set: 392.3684\n",
      "[0.82535236 0.74403571 0.66297019 0.78775792 0.84182682 0.84914235\n",
      " 0.84577427 0.58479078 0.5549593  0.80109315]\n"
     ]
    }
   ],
   "source": [
    "X = rapperswil.drop(columns=['facility', 'taken_digit', 'taken_paper', 'taken_all', 'perc_free', 'occupied'])\n",
    "print(X.columns)\n",
    "y = rapperswil['perc_free']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.6, random_state=13, shuffle = False)\n",
    "\n",
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 4,\n",
    "          'min_samples_split': 5,\n",
    "          'learning_rate': 0.1,\n",
    "          'loss': 'ls'}\n",
    "\n",
    "cv = KFold(n_splits=10, shuffle=False)\n",
    "\n",
    "reg_rap = GBR(**params)\n",
    "reg_rap.fit(X_train, y_train)\n",
    "scores = cross_val_score(reg_rap, X, y, scoring='r2', cv=cv, n_jobs=-1)\n",
    "\n",
    "mse = mean_squared_error(y_test, reg_rap.predict(X_test))\n",
    "print(\"The mean squared error (MSE) on test set: {:.4f}\".format(mse))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "falling-upset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       max_spots  weekend  weekday\n",
      "8784         155        0        4\n",
      "8785         155        0        4\n",
      "8786         155        0        4\n",
      "8787         155        0        4\n",
      "8788         155        0        4\n",
      "...          ...      ...      ...\n",
      "10193        155        1        6\n",
      "10194        155        1        6\n",
      "10195        155        1        6\n",
      "10196        155        1        6\n",
      "10197        155        1        6\n",
      "\n",
      "[1412 rows x 3 columns]\n",
      "The mean squared error (MSE) on test set: 173.5107\n",
      "[0.20209234 0.18102343 0.10632283 0.10560712 0.07082202 0.16911468\n",
      " 0.17791733 0.15431806 0.1858364  0.19626025]\n"
     ]
    }
   ],
   "source": [
    "X = burg.drop(columns=['ds', 'facility', 'taken_digit', 'taken_paper', 'taken_all', 'perc_free', 'extrapolated'])\n",
    "print(X)\n",
    "y = burg['perc_free']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.6, random_state=13, shuffle = True)\n",
    "\n",
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 4,\n",
    "          'min_samples_split': 5,\n",
    "          'learning_rate': 0.01,\n",
    "          'loss': 'ls'}\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "reg = GBR(**params)\n",
    "reg.fit(X_train, y_train)\n",
    "scores = cross_val_score(reg, X, y, scoring='r2', cv=cv, n_jobs=-1)\n",
    "\n",
    "mse = mean_squared_error(y_test, reg.predict(X_test))\n",
    "print(\"The mean squared error (MSE) on test set: {:.4f}\".format(mse))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "ordinary-peoples",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384/384 [==============================] - 1s 1ms/step - loss: 10798.1824\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 9367.6797\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 5958.5259\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 6869.5317\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 7898.9844\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 6067.9429\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 8982.9307\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 8758.4824\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 6962.0054\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 6620.8789\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 5716.2593\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 9162.5869\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 1s 1ms/step - loss: 7735.6006\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 8235.6152\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 5225.1387\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 9507.2246\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 7842.1304\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 8892.8076\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 8757.9922\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 9711.6172\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 5387.1426\n",
      "The mean squared error (MSE) on test set: 142.4991\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 9316.1611\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 5806.0981\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 6900.2686\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 9533.2705\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 8551.3027\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 1s 1ms/step - loss: 8084.8564\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 4726.6909\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 9266.7959\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 9420.2393\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 9755.9268\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 9239.2295\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 9890.0566\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 6509.8071\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 9630.1572\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 7901.1797\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 5131.4966\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 8832.1064\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 9099.6855\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 8119.7637\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 8159.5181\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 2576.8613\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 6379.8848\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 7881.7012\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 7471.9194\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 9048.0459\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 9537.4590\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 6979.6416\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 7197.7891\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 8613.0996\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 6659.7070\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 5756.7285\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 1002.6603\n",
      "The mean squared error (MSE) on test set: 24.8889\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 17062.8828\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 6959.7363\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 7391.1357\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 8272.5312\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 6851.4839\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 8539.8730\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 9305.4971\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 7740.4546\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 4001.6995\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 7551.9888\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 9051.3789\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 8860.9971\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 7141.0210\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 6840.4253\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 1s 1ms/step - loss: 6646.5200\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 8035.4067\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 1s 1ms/step - loss: 8049.4683\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 9300.7119\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 8176.8657\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 9028.3848\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 9997.5176\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 9480.0078\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 6217.5659\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 1s 1ms/step - loss: 8433.2910\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 870.6224\n",
      "The mean squared error (MSE) on test set: 25.7863\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 10972.7031\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 8234.9912\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 3630.8296\n",
      "The mean squared error (MSE) on test set: 680.6497\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 8021.5908\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 709.7595\n",
      "The mean squared error (MSE) on test set: 126.0610\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 9367.2734\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 2298.4114\n",
      "The mean squared error (MSE) on test set: 679.9761\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 782.0822\n",
      "The mean squared error (MSE) on test set: 470.2329\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 9462.0342\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 6821.8193\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 7046.0176\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 7944.7285\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 1018.5400\n",
      "The mean squared error (MSE) on test set: 45.0804\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 261.0985\n",
      "The mean squared error (MSE) on test set: 7.8713\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 813.6881\n",
      "The mean squared error (MSE) on test set: 33.3230\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 45939.8477\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 9132.7314\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 7029.0132\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 9460.4707\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 8823.0654\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 9797.3271\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 9615.7080\n",
      "The mean squared error (MSE) on test set: 9999.7914\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 9008.5391\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 8503.0391\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 7392.5029\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 914.6108\n",
      "The mean squared error (MSE) on test set: 87.3417\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 8383.1514\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 363.3299\n",
      "The mean squared error (MSE) on test set: 13.6866\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 1125.7637\n",
      "The mean squared error (MSE) on test set: 431.9006\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 13460.6553\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 9718.7334\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 9050.0361\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 7595.3320\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 7267.2773\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 1s 1ms/step - loss: 9460.0947\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 2590.0146\n",
      "The mean squared error (MSE) on test set: 159.6558\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 1996.4283\n",
      "The mean squared error (MSE) on test set: 143.6432\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 1070.1912\n",
      "The mean squared error (MSE) on test set: 62.1768\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 37038.2539\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 9261.6475\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 9076.2939\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 7366.0483\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 1s 1ms/step - loss: 7548.2861\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 8603.3945\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 9299.4863\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 9176.4121\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 8016.9175\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 7836.4116\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 7196.9570\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 4865.6924\n",
      "The mean squared error (MSE) on test set: 503.0257\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 9373.5010\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 1267.1527\n",
      "The mean squared error (MSE) on test set: 96.8002\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 339.7692\n",
      "The mean squared error (MSE) on test set: 17.2244\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 9319.3223\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 1033.0183\n",
      "The mean squared error (MSE) on test set: 256.0864\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 1652.7206\n",
      "The mean squared error (MSE) on test set: 575.9082\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 1358.5784\n",
      "The mean squared error (MSE) on test set: 556.8887\n",
      "384/384 [==============================] - 1s 1ms/step - loss: 4420.2754\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 893.3234\n",
      "The mean squared error (MSE) on test set: 90.5766\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 610.3423\n",
      "The mean squared error (MSE) on test set: 91.0911\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 1317.1663\n",
      "The mean squared error (MSE) on test set: 25.5044\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 452.3542\n",
      "The mean squared error (MSE) on test set: 336.2054\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 303.5272\n",
      "The mean squared error (MSE) on test set: 13.2406\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 1590.0983\n",
      "The mean squared error (MSE) on test set: 560.0560\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 695.9530\n",
      "The mean squared error (MSE) on test set: 47.2297\n",
      "384/384 [==============================] - 1s 1ms/step - loss: 439.5118\n",
      "The mean squared error (MSE) on test set: 40.3257\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 555.9838\n",
      "The mean squared error (MSE) on test set: 145.1076\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 123.2468\n",
      "The mean squared error (MSE) on test set: 5.1585\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 1890.8904\n",
      "The mean squared error (MSE) on test set: 2058.6687\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 244.2089\n",
      "The mean squared error (MSE) on test set: 17.1698\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 259.9022\n",
      "The mean squared error (MSE) on test set: 16.0414\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 82.5159\n",
      "The mean squared error (MSE) on test set: 9.8652\n",
      "384/384 [==============================] - 1s 1ms/step - loss: 1362.3524\n",
      "The mean squared error (MSE) on test set: 565.5266\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 1568.5995\n",
      "The mean squared error (MSE) on test set: 1093.5305\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 720.5988\n",
      "The mean squared error (MSE) on test set: 143.8752\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 417.0890\n",
      "The mean squared error (MSE) on test set: 262.3958\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 380.2188\n",
      "The mean squared error (MSE) on test set: 149.5078\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 1184.8081\n",
      "The mean squared error (MSE) on test set: 220.0404\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 910.8750\n",
      "The mean squared error (MSE) on test set: 63.2463\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 11331.1182\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 7298.0806\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 7774.1396\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 9520.4297\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 654.9142\n",
      "The mean squared error (MSE) on test set: 119.7209\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 9739.0283\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 619.8805\n",
      "The mean squared error (MSE) on test set: 50.3438\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 8151.0156\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 320.2578\n",
      "The mean squared error (MSE) on test set: 23.2058\n",
      "384/384 [==============================] - 1s 1ms/step - loss: 7745.1611\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 7355.2441\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 82.8597\n",
      "The mean squared error (MSE) on test set: 3.5275\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 790.0757\n",
      "The mean squared error (MSE) on test set: 149.8240\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 924.6192\n",
      "The mean squared error (MSE) on test set: 110.8682\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 10104.5889\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 9367.0322\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 7969.0171\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 7722.7197\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 9210.4082\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 8634.7881\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 9650.6514\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 1s 1ms/step - loss: 9535.2148\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 1s 1ms/step - loss: 5174.1265\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 1s 1ms/step - loss: 9478.8936\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 8163.3496\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 1s 1ms/step - loss: 9851.2041\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 1s 1ms/step - loss: 6581.9858\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 1s 1ms/step - loss: 6575.9780\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 9608.4414\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 4891.1475\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 1s 1ms/step - loss: 9695.4395\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 1s 1ms/step - loss: 6934.9253\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 1s 1ms/step - loss: 9172.4893\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 5946.8223\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 1s 1ms/step - loss: 6846.2832\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 1s 1ms/step - loss: 9613.4707\n",
      "The mean squared error (MSE) on test set: 10000.0000\n",
      "384/384 [==============================] - 1s 1ms/step - loss: nan\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-249-5d1ce9d32c67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The mean squared error (MSE) on test set: {:.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    334\u001b[0m     \"\"\"\n\u001b[1;32m    335\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0;32m--> 336\u001b[0;31m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[1;32m    337\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 664\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     (type_err,\n\u001b[0;32m--> 106\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m    107\u001b[0m             )\n\u001b[1;32m    108\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "reg = SGDRegressor()\n",
    "for facility in os.listdir('tables/'):\n",
    "    df = pd.read_csv('tables/' + facility)\n",
    "    X = df.drop(columns = ['ds', 'facility', 'taken_digit', 'perc_free', 'extrapolated'])\n",
    "    y = df['perc_free']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=13, shuffle = False)                       \n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    mse = mean_squared_error(y_test, model.predict(X_test))\n",
    "    print(\"The mean squared error (MSE) on test set: {:.4f}\".format(mse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "treated-tongue",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "files = os.listdir('tables/')\n",
    "merged = pd.read_csv('tables/' + files[0])\n",
    "for facility in files[1:]:\n",
    "    if facility[0] != '.':\n",
    "        merged = pd.concat([merged, pd.read_csv('tables/' + facility)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "determined-spectrum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ds', 'facility', 'max_spots', 'weekend', 'weekday', 'hour', 'month',\n",
       "       'day', 'traffic', 'taken_digit', 'extrapolated', 'perc_free',\n",
       "       'facility_id', 'probability'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bottom-rates",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "def classify_perc(x):\n",
    "    if x > 66:\n",
    "        return 2\n",
    "    if x < 33:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "enc = OrdinalEncoder()\n",
    "merged['facility_id'] = merged['facility']\n",
    "merged['facility_id'] = enc.fit_transform(np.array(merged['facility_id']).reshape(-1,1))\n",
    "merged['probability'] = merged['perc_free'].map(classify_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "grand-zealand",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('complete_sbb_data.csv').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "local-conditioning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8908437929267614\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(columns = ['ds', 'facility', 'taken_digit', 'perc_free', 'extrapolated', 'probability'])\n",
    "y = data['probability']\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=13, shuffle = False) \n",
    "\n",
    "classificator = GradientBoostingClassifier()\n",
    "classificator = classificator.fit(X_train, y_train)\n",
    "sc = classificator.score(X_test, y_test)\n",
    "print(sc)\n",
    "#scores = cross_val_score(classificator, X, y, cv=cv, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fundamental-outreach",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn, pickle\n",
    "pkl_filename = \"pickle_model.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(classificator, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "generic-third",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc = rfc.fit(X_train, y_train)\n",
    "sc = rfc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "grateful-clothing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8850467493771628\n"
     ]
    }
   ],
   "source": [
    "print(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "domestic-hazard",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type int).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36mnormalize_element\u001b[0;34m(element, element_signature)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m           \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_spec_from_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_fallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36mtype_spec_from_value\u001b[0;34m(element, use_fallback)\u001b[0m\n\u001b[1;32m    479\u001b[0m   raise TypeError(\"Could not build a TypeSpec for %r with type %s\" %\n\u001b[0;32m--> 480\u001b[0;31m                   (element, type(element).__name__))\n\u001b[0m\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not build a TypeSpec for                               ds    facility  max_spots  weekend  weekday  \\\n0      2020-01-01 00:00:00+00:00    Martigny         36        0        2   \n1      2020-01-01 01:00:00+00:00    Martigny         36        0        2   \n2      2020-01-01 02:00:00+00:00    Martigny         36        0        2   \n3      2020-01-01 03:00:00+00:00    Martigny         36        0        2   \n4      2020-01-01 04:00:00+00:00    Martigny         36        0        2   \n...                          ...         ...        ...      ...      ...   \n17539  2021-12-31 19:00:00+00:00  Effretikon         58        0        4   \n17540  2021-12-31 20:00:00+00:00  Effretikon         58        0        4   \n17541  2021-12-31 21:00:00+00:00  Effretikon         58        0        4   \n17542  2021-12-31 22:00:00+00:00  Effretikon         58        0        4   \n17543  2021-12-31 23:00:00+00:00  Effretikon         58        0        4   \n\n       hour  month  day  traffic  taken_digit  extrapolated  perc_free  \n0         0      1    1   8200.0            0             0      100.0  \n1         1      1    1   8200.0            0             0      100.0  \n2         2      1    1   8200.0            0             0      100.0  \n3         3      1    1   8200.0            0             0      100.0  \n4         4      1    1   8200.0            0             0      100.0  \n...     ...    ...  ...      ...          ...           ...        ...  \n17539    19     12   31  17000.0            0             0      100.0  \n17540    20     12   31  17000.0            0             0      100.0  \n17541    21     12   31  17000.0            0             0      100.0  \n17542    22     12   31  17000.0            0             0      100.0  \n17543    23     12   31  17000.0            0             0      100.0  \n\n[7228128 rows x 12 columns] with type DataFrame",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-5a68d8d85d0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'ds'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'facility'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'taken_digit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'perc_free'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'extrapolated'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerged\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'perc_free'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1062\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mslice_inputs\u001b[0;34m(self, indices_dataset, inputs)\u001b[0m\n\u001b[1;32m    379\u001b[0m     dataset = dataset_ops.DatasetV2.zip((\n\u001b[1;32m    380\u001b[0m         \u001b[0mindices_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m         \u001b[0mdataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDatasetV2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m     ))\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensors\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    611\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m     \"\"\"\n\u001b[0;32m--> 613\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, element)\u001b[0m\n\u001b[1;32m   3134\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3135\u001b[0m     \u001b[0;34m\"\"\"See `Dataset.from_tensors()` for details.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3136\u001b[0;31m     \u001b[0melement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3137\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_spec_from_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3138\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36mnormalize_element\u001b[0;34m(element, element_signature)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;31m# the value. As a fallback try converting the value to a tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         normalized_components.append(\n\u001b[0;32m--> 111\u001b[0;31m             ops.convert_to_tensor(t, name=\"component_%d\" % i))\n\u001b[0m\u001b[1;32m    112\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensorSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1540\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    337\u001b[0m                                          as_ref=False):\n\u001b[1;32m    338\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    263\u001b[0m   \"\"\"\n\u001b[1;32m    264\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 265\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m   \u001b[0;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type int)."
     ]
    }
   ],
   "source": [
    "model.fit(merged)\n",
    "X = merged.drop(columns = ['ds', 'facility', 'taken_digit', 'perc_free', 'extrapolated'])\n",
    "y = merged['perc_free']\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "scores = cross_val_score(model, X, y, scoring='r2', cv=cv, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "cardiovascular-denver",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn, pickle\n",
    "pkl_filename = \"pickle_model.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(reg, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "filled-logan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (394.3 MB)\n",
      "\u001b[K     |██████████████████████████▎     | 323.5 MB 96.2 MB/s eta 0:00:012"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 394.3 MB 8.7 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting absl-py~=0.10\n",
      "  Downloading absl_py-0.12.0-py3-none-any.whl (129 kB)\n",
      "\u001b[K     |████████████████████████████████| 129 kB 79.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio~=1.32.0\n",
      "  Downloading grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 29.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: six~=1.15.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.15.0)\n",
      "Collecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting google-pasta~=0.2\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 6.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting h5py~=2.10.0\n",
      "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 79.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Requirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.36.2)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 4.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions~=3.7.4 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.12.1)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 1.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.5.0,>=2.4.0\n",
      "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 79.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.15.2)\n",
      "Collecting tensorboard~=2.4\n",
      "  Downloading tensorboard-2.4.1-py3-none-any.whl (10.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.6 MB 81.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (49.6.0.post20210108)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (3.3.3)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "\u001b[K     |████████████████████████████████| 298 kB 81.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (0.4.2)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 69.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (1.24.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.7)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.26.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.4.0)\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=7a3d6efdec9a535c6643d7eb53ea565cfbb4c6136e6466316252013d9b64b585\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
      "Successfully built termcolor\n",
      "Installing collected packages: werkzeug, tensorboard-plugin-wit, grpcio, absl-py, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.36.0\n",
      "    Uninstalling grpcio-1.36.0:\n",
      "      Successfully uninstalled grpcio-1.36.0\n",
      "Successfully installed absl-py-0.12.0 astunparse-1.6.3 flatbuffers-1.12 gast-0.3.3 google-pasta-0.2.0 grpcio-1.32.0 h5py-2.10.0 keras-preprocessing-1.1.2 opt-einsum-3.3.0 tensorboard-2.4.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.4.1 tensorflow-estimator-2.4.0 termcolor-1.1.0 werkzeug-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "unauthorized-bridges",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "rubber-parts",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    input_layer = Input(shape=(8), dtype='float32')\n",
    "    dense1 = Dense(64, activation=activations.swish)(input_layer)\n",
    "    dense2 = Dense(128, activation=activations.swish)(dense1)\n",
    "    dense3 = Dense(64, activation=activations.sigmoid)(dense2)\n",
    "    dropout_layer = Dropout(0.3)(dense3)\n",
    "    output_layer = Dense(3, activation=activations.sigmoid)(dropout_layer)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(loss='categorical_crossentropy', metrics=[\"accuracy\"], optimizer='SGD')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "imposed-regression",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 7)]               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 60)                480       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 183       \n",
      "=================================================================\n",
      "Total params: 4,323\n",
      "Trainable params: 4,323\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conceptual-firewall",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KerasClassifier(build_fn = baseline_model, epochs = 7, batch_size = 64, verbose = 0)\n",
    "kfold = KFold(n_splits = 5, shuffle = True, random_state = 0)\n",
    "# Object to describe the result\n",
    "results = cross_val_score(estimator, X, y, cv = kfold)\n",
    "# Result\n",
    "print(\"Result: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "sorted-moderator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.json/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('model.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "alive-league",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: model.json/ (stored 0%)\n",
      "  adding: model.json/saved_model.pb (deflated 88%)\n",
      "  adding: model.json/assets/ (stored 0%)\n",
      "  adding: model.json/variables/ (stored 0%)\n",
      "  adding: model.json/variables/variables.data-00000-of-00001 (deflated 18%)\n",
      "  adding: model.json/variables/variables.index (deflated 48%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r model.zip \"model.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "threaded-agency",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\", line 223, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\", line 166, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\", line 1100, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 828, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 871, in _call\n",
      "    self._initialize(args, kwds, add_initializers_to=initializers)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 726, in _initialize\n",
      "    *args, **kwds))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 2969, in _get_concrete_function_internal_garbage_collected\n",
      "    graph_function, _ = self._maybe_define_function(args, kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 3361, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 3206, in _create_graph_function\n",
      "    capture_by_value=self._capture_by_value),\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\", line 990, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 634, in wrapped_fn\n",
      "    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\", line 977, in wrapper\n",
      "    raise e.ag_error_metadata.to_exception(e)\n",
      "ValueError: in user code:\n",
      "\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n",
      "        return step_function(self, iterator)\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n",
      "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n",
      "        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n",
      "        return self._call_for_each_replica(fn, args, kwargs)\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n",
      "        return fn(*args, **kwargs)\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n",
      "        outputs = model.train_step(data)\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:754 train_step\n",
      "        y_pred = self(x, training=True)\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n",
      "        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:274 assert_input_compatibility\n",
      "        ', found shape=' + display_shape(x.shape))\n",
      "\n",
      "    ValueError: Input 0 is incompatible with layer model_1: expected shape=(None, 7), found shape=(None, 8)\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\", line 223, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\", line 166, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\", line 1100, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 828, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 871, in _call\n",
      "    self._initialize(args, kwds, add_initializers_to=initializers)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 726, in _initialize\n",
      "    *args, **kwds))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 2969, in _get_concrete_function_internal_garbage_collected\n",
      "    graph_function, _ = self._maybe_define_function(args, kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 3361, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 3206, in _create_graph_function\n",
      "    capture_by_value=self._capture_by_value),\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\", line 990, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 634, in wrapped_fn\n",
      "    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\", line 977, in wrapper\n",
      "    raise e.ag_error_metadata.to_exception(e)\n",
      "ValueError: in user code:\n",
      "\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n",
      "        return step_function(self, iterator)\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n",
      "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n",
      "        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n",
      "        return self._call_for_each_replica(fn, args, kwargs)\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n",
      "        return fn(*args, **kwargs)\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n",
      "        outputs = model.train_step(data)\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:754 train_step\n",
      "        y_pred = self(x, training=True)\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n",
      "        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:274 assert_input_compatibility\n",
      "        ', found shape=' + display_shape(x.shape))\n",
      "\n",
      "    ValueError: Input 0 is incompatible with layer model_2: expected shape=(None, 7), found shape=(None, 8)\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\", line 223, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\", line 166, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\", line 1100, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 828, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 871, in _call\n",
      "    self._initialize(args, kwds, add_initializers_to=initializers)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 726, in _initialize\n",
      "    *args, **kwds))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 2969, in _get_concrete_function_internal_garbage_collected\n",
      "    graph_function, _ = self._maybe_define_function(args, kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 3361, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 3206, in _create_graph_function\n",
      "    capture_by_value=self._capture_by_value),\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\", line 990, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 634, in wrapped_fn\n",
      "    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\", line 977, in wrapper\n",
      "    raise e.ag_error_metadata.to_exception(e)\n",
      "ValueError: in user code:\n",
      "\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n",
      "        return step_function(self, iterator)\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n",
      "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n",
      "        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n",
      "        return self._call_for_each_replica(fn, args, kwargs)\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n",
      "        return fn(*args, **kwargs)\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n",
      "        outputs = model.train_step(data)\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:754 train_step\n",
      "        y_pred = self(x, training=True)\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n",
      "        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:274 assert_input_compatibility\n",
      "        ', found shape=' + display_shape(x.shape))\n",
      "\n",
      "    ValueError: Input 0 is incompatible with layer model_3: expected shape=(None, 7), found shape=(None, 8)\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\", line 223, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\", line 166, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\", line 1100, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 828, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 871, in _call\n",
      "    self._initialize(args, kwds, add_initializers_to=initializers)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 726, in _initialize\n",
      "    *args, **kwds))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 2969, in _get_concrete_function_internal_garbage_collected\n",
      "    graph_function, _ = self._maybe_define_function(args, kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 3361, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 3206, in _create_graph_function\n",
      "    capture_by_value=self._capture_by_value),\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\", line 990, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 634, in wrapped_fn\n",
      "    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\", line 977, in wrapper\n",
      "    raise e.ag_error_metadata.to_exception(e)\n",
      "ValueError: in user code:\n",
      "\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n",
      "        return step_function(self, iterator)\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n",
      "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n",
      "        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n",
      "        return self._call_for_each_replica(fn, args, kwargs)\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n",
      "        return fn(*args, **kwargs)\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n",
      "        outputs = model.train_step(data)\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:754 train_step\n",
      "        y_pred = self(x, training=True)\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n",
      "        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:274 assert_input_compatibility\n",
      "        ', found shape=' + display_shape(x.shape))\n",
      "\n",
      "    ValueError: Input 0 is incompatible with layer model_4: expected shape=(None, 7), found shape=(None, 8)\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: nan% (nan%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\", line 223, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\", line 166, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\", line 1100, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 828, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 871, in _call\n",
      "    self._initialize(args, kwds, add_initializers_to=initializers)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 726, in _initialize\n",
      "    *args, **kwds))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 2969, in _get_concrete_function_internal_garbage_collected\n",
      "    graph_function, _ = self._maybe_define_function(args, kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 3361, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 3206, in _create_graph_function\n",
      "    capture_by_value=self._capture_by_value),\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\", line 990, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 634, in wrapped_fn\n",
      "    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\", line 977, in wrapper\n",
      "    raise e.ag_error_metadata.to_exception(e)\n",
      "ValueError: in user code:\n",
      "\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n",
      "        return step_function(self, iterator)\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n",
      "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n",
      "        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n",
      "        return self._call_for_each_replica(fn, args, kwargs)\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n",
      "        return fn(*args, **kwargs)\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n",
      "        outputs = model.train_step(data)\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:754 train_step\n",
      "        y_pred = self(x, training=True)\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n",
      "        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n",
      "    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:274 assert_input_compatibility\n",
      "        ', found shape=' + display_shape(x.shape))\n",
      "\n",
      "    ValueError: Input 0 is incompatible with layer model_5: expected shape=(None, 7), found shape=(None, 8)\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(columns = ['ds', 'facility', 'taken_digit', 'perc_free', 'extrapolated', 'probability'])\n",
    "y = data['probability']\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m65"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
